# å¢å¼·å‹è«–æ–‡åˆ†æç³»çµ±å·¥ä½œæµç¨‹

## ç³»çµ±æ¦‚è¿°

æœ¬ç³»çµ±æ˜¯ä¸€å€‹åŸºæ–¼PostgreSQLè³‡æ–™åº«çš„å­¸è¡“è«–æ–‡åˆ†æå¹³å°ï¼Œæ•´åˆGrobidé€²è¡Œæ–‡æª”åˆ†å€è™•ç†ï¼Œæ”¯æ´å¤šæª”æ¡ˆæ©«å‘æ¯”è¼ƒèˆ‡æ·±åº¦åˆ†æã€‚ç³»çµ±åˆ†ç‚ºå…©å€‹ä¸»è¦å·¥ä½œæµï¼š**è³‡æ–™æº–å‚™éšæ®µ**å’Œ**ä½¿ç”¨è€…ç™¼å•éšæ®µ**ã€‚

## æŠ€è¡“æ¶æ§‹

### æ ¸å¿ƒæŠ€è¡“æ£§
- **å‰ç«¯**: React 18 + TypeScript + TailwindCSS
- **è³‡æ–™åº«**: PostgreSQL 
- **æ–‡æª”è™•ç†**: Grobid (Dockeréƒ¨ç½²)
- **å¥å­åˆ†æ**: N8N Workflow APIs
- **å¾Œç«¯API**: FastAPI (æ‰¹æ¬¡è™•ç†èˆ‡ä½‡åˆ—ç®¡ç†)
- **ç‹€æ…‹ç®¡ç†**: Zustand + React Query

### è³‡æ–™åº«çµæ§‹

```sql
-- è«–æ–‡ç®¡ç†è¡¨ (åŠ å…¥TEI XMLå„²å­˜ï¼Œç°¡åŒ–ä½¿ç”¨è€…ç®¡ç†)
CREATE TABLE papers (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    file_name VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255),
    upload_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processing_status VARCHAR(50) DEFAULT 'uploading',
    file_size BIGINT,
    file_hash VARCHAR(64) UNIQUE, -- ç”¨æ–¼æª”æ¡ˆå»é‡
    grobid_processed BOOLEAN DEFAULT FALSE,
    sentences_processed BOOLEAN DEFAULT FALSE,
    pdf_deleted BOOLEAN DEFAULT FALSE, -- æ¨™è¨˜PDFæ˜¯å¦å·²åˆªé™¤
    error_message TEXT,
    -- TEI XML å„²å­˜ (æ–°å¢)
    tei_xml TEXT, -- å„²å­˜å®Œæ•´çš„Grobid TEI XML
    tei_metadata JSONB, -- å„²å­˜è§£æå¾Œçš„metadata (ä½œè€…ã€æ¨™é¡Œç­‰)
    processing_completed_at TIMESTAMP, -- è™•ç†å®Œæˆæ™‚é–“
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è«–æ–‡åˆ†å€è¡¨
CREATE TABLE paper_sections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    paper_id UUID REFERENCES papers(id) ON DELETE CASCADE,
    section_type VARCHAR(50) NOT NULL, -- introduction, abstract, method, etc.
    page_num INTEGER,
    content TEXT NOT NULL,
    section_order INTEGER,
    -- æ–°å¢TEIç›¸é—œæ¬„ä½
    tei_coordinates JSONB, -- å„²å­˜TEIåº§æ¨™è³‡è¨Š
    word_count INTEGER, -- ç« ç¯€å­—æ•¸
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å¥å­è³‡æ–™è¡¨  
CREATE TABLE sentences (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    paper_id UUID REFERENCES papers(id) ON DELETE CASCADE,
    section_id UUID REFERENCES paper_sections(id) ON DELETE CASCADE,
    sentence_text TEXT NOT NULL,
    page_num INTEGER,
    sentence_order INTEGER,
    defining_type VARCHAR(20) DEFAULT 'UNKNOWN', -- OD, CD, OTHER, UNKNOWN
    analysis_reason TEXT,
    -- æ–°å¢æ¬„ä½
    word_count INTEGER, -- å¥å­å­—æ•¸
    confidence_score DECIMAL(3,2), -- OD/CDåˆ†æä¿¡å¿ƒåº¦
    processed_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å…¨åŸŸè«–æ–‡é¸æ“‡ç‹€æ…‹è¡¨ (ç°¡åŒ–ç‚ºå–®ä¸€ä½¿ç”¨è€…æ¨¡å¼)
CREATE TABLE paper_selections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    paper_id UUID REFERENCES papers(id) ON DELETE CASCADE,
    is_selected BOOLEAN DEFAULT TRUE,
    selected_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(paper_id)
);

-- è™•ç†ä½‡åˆ—è¡¨ (ç”¨æ–¼FastAPIå¾Œç«¯æ‰¹æ¬¡è™•ç†)
CREATE TABLE processing_queue (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    paper_id UUID REFERENCES papers(id) ON DELETE CASCADE,
    processing_stage VARCHAR(50) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending', -- pending, processing, completed, failed
    priority INTEGER DEFAULT 0,
    retry_count INTEGER DEFAULT 0, -- é‡è©¦æ¬¡æ•¸
    max_retries INTEGER DEFAULT 3, -- æœ€å¤§é‡è©¦æ¬¡æ•¸
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    error_message TEXT,
    processing_details JSONB -- å„²å­˜è™•ç†éç¨‹çš„è©³ç´°è³‡è¨Š
);

-- ç³»çµ±è¨­å®šè¡¨ (ç”¨æ–¼å­˜æ”¾å…¨åŸŸè¨­å®š)
CREATE TABLE system_settings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    setting_key VARCHAR(100) UNIQUE NOT NULL,
    setting_value JSONB,
    description TEXT,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å»ºç«‹ç´¢å¼•ä»¥æå‡æŸ¥è©¢æ•ˆèƒ½
CREATE INDEX idx_papers_hash ON papers(file_hash);
CREATE INDEX idx_papers_status ON papers(processing_status);
CREATE INDEX idx_sentences_defining_type ON sentences(defining_type);
CREATE INDEX idx_sentences_paper_section ON sentences(paper_id, section_id);
CREATE INDEX idx_processing_queue_status ON processing_queue(status, priority);
```

## å·¥ä½œæµç¨‹ä¸€ï¼šè³‡æ–™æº–å‚™éšæ®µ

### æµç¨‹åœ–
```mermaid
graph TD
    A[ä½¿ç”¨è€…ä¸Šå‚³PDF] --> B[æª¢æŸ¥æª”æ¡ˆé›œæ¹Š]
    B --> C{æª”æ¡ˆå·²å­˜åœ¨?}
    C -->|æ˜¯| D[è¼‰å…¥å·²å­˜åœ¨è³‡æ–™]
    C -->|å¦| E[å„²å­˜æª”æ¡ˆè³‡è¨Šåˆ°è³‡æ–™åº«]
    E --> F[åŠ å…¥è™•ç†ä½‡åˆ—]
    F --> G[Grobid TEIè™•ç†]
    G --> H[è§£æTEIä¸¦å„²å­˜åˆ†å€]
    H --> I[é€å€å¥å­åˆ‡åˆ†]
    I --> J[OD/CDåˆ†æ]
    J --> K[å„²å­˜å¥å­è³‡æ–™]
    K --> L[æ¨™è¨˜è™•ç†å®Œæˆ]
    D --> L
```

### è©³ç´°å¯¦ä½œæ­¥é©Ÿ

#### æ­¥é©Ÿ1: å‰ç«¯æª”æ¡ˆä¸Šå‚³ (é€éFastAPI)
```typescript
// å‰ç«¯æª”æ¡ˆä¸Šå‚³æœå‹™ - å®Œå…¨é€éAPIæ“ä½œ
class FileUploadService {
  private readonly apiBaseUrl = 'http://localhost:8000/api';
  
  async uploadFile(file: File): Promise<UploadResult> {
    const formData = new FormData();
    formData.append('file', file);
    
    try {
      const response = await fetch(`${this.apiBaseUrl}/papers/upload`, {
        method: 'POST',
        body: formData,
      });
      
      if (!response.ok) {
        throw new Error(`Upload failed: ${response.statusText}`);
      }
      
      const result = await response.json();
      
      // è‡ªå‹•é–‹å§‹ç›£æ§è™•ç†é€²åº¦
      if (result.status === 'uploaded') {
        this.startProgressMonitoring(result.paper_id);
      }
      
      return result;
      
    } catch (error) {
      throw new Error(`æª”æ¡ˆä¸Šå‚³å¤±æ•—: ${error.message}`);
    }
  }
  
  // ç›£æ§è™•ç†é€²åº¦
  private async startProgressMonitoring(paperId: string): Promise<void> {
    const interval = setInterval(async () => {
      try {
        const status = await this.getProcessingStatus(paperId);
        
        // æ›´æ–°å‰ç«¯é€²åº¦é¡¯ç¤º
        this.updateProgressUI(paperId, status);
        
        // å¦‚æœå®Œæˆæˆ–å¤±æ•—ï¼Œåœæ­¢ç›£æ§
        if (status.status === 'completed' || status.status === 'error') {
          clearInterval(interval);
          
          if (status.status === 'completed') {
            // é‡æ–°è¼‰å…¥è«–æ–‡æ¸…å–®
            await this.refreshPapersList();
            this.showSuccessMessage(`${status.paper_id} è™•ç†å®Œæˆï¼`);
          } else {
            this.showErrorMessage(`è™•ç†å¤±æ•—: ${status.error_message}`, paperId);
          }
        }
        
      } catch (error) {
        console.error('Failed to get processing status:', error);
      }
    }, 2000); // æ¯2ç§’æª¢æŸ¥ä¸€æ¬¡
  }
  
  async getProcessingStatus(paperId: string): Promise<ProcessingStatus> {
    const response = await fetch(`${this.apiBaseUrl}/papers/${paperId}/status`);
    return await response.json();
  }
  
  async retryProcessing(paperId: string): Promise<void> {
    const response = await fetch(`${this.apiBaseUrl}/papers/${paperId}/retry`, {
      method: 'POST'
    });
    
    if (response.ok) {
      this.startProgressMonitoring(paperId);
    }
  }
}

// è«–æ–‡ç®¡ç†æœå‹™ - çµ±ä¸€APIæ¥å£
class PaperManagementService {
  private readonly apiBaseUrl = 'http://localhost:8000/api';
  
  // å–å¾—æ‰€æœ‰è«–æ–‡
  async getAllPapers(): Promise<Paper[]> {
    const response = await fetch(`${this.apiBaseUrl}/papers`);
    return await response.json();
  }
  
  // å–å¾—å·²é¸å–è«–æ–‡
  async getSelectedPapers(): Promise<Paper[]> {
    const response = await fetch(`${this.apiBaseUrl}/papers/selected`);
    return await response.json();
  }
  
  // åˆ‡æ›è«–æ–‡é¸å–ç‹€æ…‹
  async togglePaperSelection(paperId: string, isSelected: boolean): Promise<void> {
    await fetch(`${this.apiBaseUrl}/papers/${paperId}/select`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ is_selected: isSelected })
    });
  }
  
  // å…¨é¸è«–æ–‡
  async selectAllPapers(): Promise<void> {
    await fetch(`${this.apiBaseUrl}/papers/select_all`, {
      method: 'POST'
    });
  }
  
  // å–æ¶ˆå…¨é¸
  async deselectAllPapers(): Promise<void> {
    await fetch(`${this.apiBaseUrl}/papers/deselect_all`, {
      method: 'POST'
    });
  }
}

// æŸ¥è©¢è™•ç†æœå‹™
class QueryService {
  private readonly apiBaseUrl = 'http://localhost:8000/api';
  
  async processQuery(query: string): Promise<QueryResult> {
    const response = await fetch(`${this.apiBaseUrl}/query/process`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query })
    });
    
    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.detail || 'æŸ¥è©¢è™•ç†å¤±æ•—');
    }
    
    return await response.json();
  }
}
```

#### æ­¥é©Ÿ2: Grobid TEIè™•ç†
```typescript
class GrobidService {
  private readonly grobidBaseUrl = 'http://140.115.126.192:8070';
  
  async processDocument(paperId: string): Promise<GrobidTEIResult> {
    const fileBuffer = await this.getFileBuffer(paperId);
    
    // èª¿ç”¨Grobid API
    const response = await axios.post(
      `${this.grobidBaseUrl}/api/processFulltextDocument`,
      {
        input: fileBuffer,
        consolidateHeader: 1,
        consolidateCitations: 1,
        includeRawCitations: 1,
        includeRawAffiliations: 1,
        teiCoordinates: ['persName', 'figure', 'ref', 'biblStruct'],
        segmentSentences: 1
      },
      {
        headers: { 'Content-Type': 'multipart/form-data' },
        timeout: 300000 // 5åˆ†é˜è¶…æ™‚
      }
    );
    
    return this.parseTEIResponse(response.data);
  }
  
  private parseTEIResponse(teiXML: string): GrobidTEIResult {
    // è§£æTEI XMLï¼Œæå–ç« ç¯€è³‡è¨Š
    const parser = new DOMParser();
    const doc = parser.parseFromString(teiXML, 'text/xml');
    
    const sections: TEISection[] = [];
    
    // è§£æä¸åŒç« ç¯€
    const divElements = doc.querySelectorAll('div[type]');
    divElements.forEach((div, index) => {
      const sectionType = div.getAttribute('type') || 'unknown';
      const content = this.extractTextContent(div);
      const pageInfo = this.extractPageInfo(div);
      
      sections.push({
        type: this.normalizeSectionType(sectionType),
        content: content,
        page_start: pageInfo.start,
        page_end: pageInfo.end,
        order: index
      });
    });
    
    return { sections, metadata: this.extractMetadata(doc) };
  }
  
  private normalizeSectionType(type: string): string {
    const mapping: Record<string, string> = {
      'introduction': 'introduction',
      'related-work': 'related_work', 
      'methodology': 'method',
      'method': 'method',
      'results': 'results',
      'discussion': 'discussion',
      'conclusion': 'conclusion',
      'abstract': 'abstract',
      'references': 'references'
    };
    
    return mapping[type.toLowerCase()] || 'other';
  }
}
```

#### æ­¥é©Ÿ3: å¥å­è™•ç†èˆ‡åˆ†æ
```typescript
class SentenceProcessor {
  async processPaperSections(paperId: string, sections: TEISection[]): Promise<void> {
    for (const section of sections) {
      // å„²å­˜åˆ†å€è³‡è¨Š
      const sectionId = await this.db.createPaperSection({
        paper_id: paperId,
        section_type: section.type,
        page_num: section.page_start,
        content: section.content,
        section_order: section.order
      });
      
      // å¥å­åˆ‡åˆ†
      const sentences = await this.splitSentencesAPI.process(section.content);
      
      // é€å¥åˆ†æ
      await this.processSentencesInSection(paperId, sectionId, sentences, section.page_start);
    }
  }
  
  private async processSentencesInSection(
    paperId: string, 
    sectionId: string, 
    sentences: string[], 
    pageNum: number
  ): Promise<void> {
    for (let i = 0; i < sentences.length; i++) {
      const sentence = sentences[i];
      
      try {
        // OD/CDåˆ†æ
        const analysis = await this.n8nAPI.checkOdCd(sentence);
        
        // å„²å­˜å¥å­
        await this.db.createSentence({
          paper_id: paperId,
          section_id: sectionId,
          sentence_text: sentence,
          page_num: pageNum,
          sentence_order: i,
          defining_type: analysis.defining_type.toUpperCase(),
          analysis_reason: analysis.reason
        });
        
        // æ›´æ–°é€²åº¦
        await this.updateProgress(paperId, 'sentence_analysis', i + 1, sentences.length);
        
      } catch (error) {
        console.error(`Error processing sentence ${i}:`, error);
        // å„²å­˜æœªåˆ†æçš„å¥å­
        await this.db.createSentence({
          paper_id: paperId,
          section_id: sectionId,
          sentence_text: sentence,
          page_num: pageNum,
          sentence_order: i,
          defining_type: 'UNKNOWN',
          analysis_reason: `Processing error: ${error.message}`
        });
      }
    }
  }
}
```

## å·¥ä½œæµç¨‹äºŒï¼šä½¿ç”¨è€…ç™¼å•éšæ®µ

### æµç¨‹åœ–
```mermaid
graph TD
    A[ä½¿ç”¨è€…ç™¼é€æŸ¥è©¢] --> B[å–å¾—å‹¾é¸æª”æ¡ˆæ¸…å–®]
    B --> C[ç²å–å„æª”æ¡ˆsectionæ‘˜è¦]
    C --> D[LLMæ™ºèƒ½é¸æ“‡ç›¸é—œsections]
    D --> E[æå–é¸ä¸­çš„sectionå…§å®¹]
    E --> F[çµ±ä¸€æ•´åˆåˆ†æå›æ‡‰]
    F --> G[é¡¯ç¤ºçµæœèˆ‡å¼•ç”¨]
```

### ç°¡åŒ–çš„çµ±ä¸€æŸ¥è©¢è™•ç†æµç¨‹

```typescript
class UnifiedQueryProcessor {
  async processQuery(query: string, selectedPapers: string[]): Promise<QueryResult> {
    // 1. ç²å–æ‰€æœ‰é¸ä¸­è«–æ–‡çš„sectionæ‘˜è¦
    const papersWithSections = await this.getPapersWithSections(selectedPapers);
    
    // 2. è®“LLMæ™ºèƒ½é¸æ“‡ç›¸é—œsections (å–ä»£æ„åœ–åˆ†é¡)
    const sectionSelectionResult = await this.n8nAPI.intelligentSectionSelection({
      query: query,
      available_papers: papersWithSections
    });
    
    // 3. æ ¹æ“šLLMé¸æ“‡ï¼Œæå–ç›¸é—œå…§å®¹
    const selectedContent = await this.extractSelectedContent(
      sectionSelectionResult.selected_sections
    );
    
    // 4. çµ±ä¸€æ•´åˆåˆ†æ (ç„¡éœ€å€åˆ†OD/CDæˆ–å…¶ä»–é¡å‹)
    const response = await this.n8nAPI.unifiedContentAnalysis({
      query: query,
      selected_content: selectedContent,
      analysis_focus: sectionSelectionResult.analysis_focus
    });
    
    return {
      response: response.response,
      references: response.references,
      selected_sections: sectionSelectionResult.selected_sections,
      analysis_focus: sectionSelectionResult.analysis_focus,
      source_summary: response.source_summary
    };
  }
  
  // å–å¾—æ‰€æœ‰è«–æ–‡çš„sectionæ¦‚è¦½
  private async getPapersWithSections(paperIds: string[]): Promise<PaperSectionSummary[]> {
    const papers = await this.db.getPapersWithSections(paperIds);
    
    return papers.map(paper => ({
      file_name: paper.file_name,
      sections: paper.sections.map(section => ({
        section_type: section.section_type,
        page_num: section.page_num,
        word_count: section.word_count,
        // æä¾›sectionçš„ç°¡çŸ­æ‘˜è¦ (å‰100å­—)
        brief_content: section.content.substring(0, 100) + '...',
        // çµ±è¨ˆè©²sectionçš„OD/CDå¥å­æ•¸é‡
        od_count: section.sentences?.filter(s => s.defining_type === 'OD').length || 0,
        cd_count: section.sentences?.filter(s => s.defining_type === 'CD').length || 0,
        total_sentences: section.sentences?.length || 0
      }))
    }));
  }
  
  // æ ¹æ“šLLMé¸æ“‡ï¼Œæå–å®Œæ•´å…§å®¹
  private async extractSelectedContent(
    selectedSections: SelectedSection[]
  ): Promise<ExtractedContent[]> {
    const extractedContent: ExtractedContent[] = [];
    
    for (const selection of selectedSections) {
      // æ ¹æ“šæŸ¥è©¢éœ€æ±‚æ±ºå®šæå–æ–¹å¼
      if (selection.focus_type === 'definitions') {
        // å¦‚æœéœ€è¦å®šç¾©ï¼Œå„ªå…ˆæå–OD/CDå¥å­
        const definitionSentences = await this.db.getDefinitionSentences({
          paper_id: selection.paper_id,
          section_id: selection.section_id,
          types: ['OD', 'CD']
        });
        
        extractedContent.push({
          paper_name: selection.paper_name,
          section_type: selection.section_type,
          content_type: 'definitions',
          content: definitionSentences.map(s => ({
            text: s.sentence_text,
            type: s.defining_type,
            page_num: s.page_num
          }))
        });
        
      } else if (selection.focus_type === 'full_section') {
        // å¦‚æœéœ€è¦å®Œæ•´å…§å®¹ï¼Œæå–æ•´å€‹section
        const sectionContent = await this.db.getSectionContent(selection.section_id);
        
        extractedContent.push({
          paper_name: selection.paper_name,
          section_type: selection.section_type,
          content_type: 'full_section',
          content: sectionContent
        });
        
      } else if (selection.focus_type === 'key_sentences') {
        // å¦‚æœéœ€è¦é—œéµå¥å­ï¼ŒåŸºæ–¼é—œéµè©æœå°‹
        const relevantSentences = await this.db.searchSentencesByKeywords({
          section_id: selection.section_id,
          keywords: selection.keywords
        });
        
        extractedContent.push({
          paper_name: selection.paper_name,
          section_type: selection.section_type,
          content_type: 'key_sentences',
          content: relevantSentences
        });
      }
    }
    
    return extractedContent;
  }
}

// å®šç¾©ç›¸é—œå‹åˆ¥
interface PaperSectionSummary {
  file_name: string;
  sections: {
    section_type: string;
    page_num: number;
    word_count: number;
    brief_content: string;
    od_count: number;
    cd_count: number;
    total_sentences: number;
  }[];
}

interface SelectedSection {
  paper_id: string;
  paper_name: string;
  section_id: string;
  section_type: string;
  focus_type: 'definitions' | 'full_section' | 'key_sentences';
  keywords?: string[];
  selection_reason: string;
}

interface ExtractedContent {
  paper_name: string;
  section_type: string;
  content_type: 'definitions' | 'full_section' | 'key_sentences';
  content: any;
}
```

## å‰ç«¯æ•´åˆèˆ‡å¼•ç”¨é¡¯ç¤º

### MessageBubbleå¢å¼·
```typescript
interface EnhancedMessage extends Message {
  source_summary?: {
    total_papers: number;
    papers_used: string[];
    sections_analyzed?: string[];
  };
}

const EnhancedMessageBubble: React.FC<{message: EnhancedMessage}> = ({ message }) => {
  const renderContentWithReferences = () => {
    const refRegex = /\[\[ref:([a-zA-Z0-9-]+)\]\]/g;
    const parts = message.content.split(refRegex);
    
    const result: React.ReactNode[] = [];
    for (let i = 0; i < parts.length; i++) {
      if (i % 2 === 0) {
        result.push(<span key={`text-${i}`}>{parts[i]}</span>);
      } else {
        const refId = parts[i];
        const reference = message.references?.find(ref => ref.id === refId);
        
        result.push(
          <button
            key={`ref-${refId}`}
            className="inline-flex items-center px-2 py-0.5 rounded-full text-xs font-medium bg-blue-100 text-blue-800 mx-1 hover:bg-blue-200"
            onClick={() => onReferenceClick?.(refId)}
            title={reference ? `${reference.file_name} - ${reference.section} (p.${reference.page_num})` : ''}
          >
            ğŸ“„ {reference?.file_name?.substring(0, 8)}...
          </button>
        );
      }
    }
    
    return <div className="whitespace-pre-wrap">{result}</div>;
  };
  
  return (
    <div className="message-bubble">
      {renderContentWithReferences()}
      
      {/* ä¾†æºæ‘˜è¦ */}
      {message.source_summary && (
        <div className="mt-2 p-2 bg-gray-50 rounded text-xs">
          <div className="font-medium">è³‡æ–™ä¾†æºæ‘˜è¦ï¼š</div>
          <div>â€¢ åˆ†æäº† {message.source_summary.total_papers} ç¯‡è«–æ–‡</div>
          <div>â€¢ ä½¿ç”¨æª”æ¡ˆï¼š{message.source_summary.papers_used.join(', ')}</div>
          {message.source_summary.sections_analyzed && (
            <div>â€¢ åˆ†æç« ç¯€ï¼š{message.source_summary.sections_analyzed.join(', ')}</div>
          )}
        </div>
      )}
    </div>
  );
};
```

## éŒ¯èª¤è™•ç†èˆ‡é‡è©¦æ©Ÿåˆ¶

### è™•ç†å¤±æ•—ç®¡ç†
```typescript
class ErrorHandler {
  async handleProcessingError(paperId: string, stage: string, error: Error): Promise<void> {
    // è¨˜éŒ„éŒ¯èª¤
    await this.db.updatePaperStatus(paperId, 'error', error.message);
    
    // æ›´æ–°è™•ç†ä½‡åˆ—
    await this.db.updateProcessingQueue(paperId, stage, 'failed', error.message);
    
    // é€šçŸ¥å‰ç«¯
    this.notifyFrontend(paperId, {
      status: 'error',
      stage: stage,
      message: error.message,
      retryable: this.isRetryableError(error)
    });
  }
  
  async retryProcessing(paperId: string, fromStage: string): Promise<void> {
    // é‡è¨­ç‹€æ…‹
    await this.db.updatePaperStatus(paperId, 'processing');
    
    // æ¸…é™¤éŒ¯èª¤è¨Šæ¯
    await this.db.clearErrorMessage(paperId);
    
    // é‡æ–°åŠ å…¥è™•ç†ä½‡åˆ—
    await this.queueForProcessing(paperId, fromStage);
  }
}
```

## FastAPIå¾Œç«¯æ¶æ§‹è¨­è¨ˆ

### æ ¸å¿ƒæ¶æ§‹
å‰ç«¯Reactå®Œå…¨é€éFastAPIèˆ‡è³‡æ–™åº«äº¤äº’ï¼Œç¢ºä¿è³‡æ–™ä¸€è‡´æ€§å’Œå®‰å…¨æ€§ã€‚

```python
# main.py - FastAPIä¸»æ‡‰ç”¨
from fastapi import FastAPI, UploadFile, File, BackgroundTasks, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
import asyncio
import uuid

app = FastAPI(title="è«–æ–‡åˆ†æç³»çµ±API", version="1.0.0")

# CORSè¨­å®š - æ”¯æ´å¤šclientæ“ä½œ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # é–‹ç™¼ç’°å¢ƒï¼Œç”Ÿç”¢ç’°å¢ƒéœ€è¦æŒ‡å®šå…·é«”åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === æª”æ¡ˆä¸Šå‚³èˆ‡ç®¡ç† ===
@app.post("/api/papers/upload")
async def upload_paper(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
):
    """ä¸Šå‚³PDFæª”æ¡ˆä¸¦é–‹å§‹è™•ç†æµç¨‹"""
    
    # 1. æª”æ¡ˆé©—è­‰
    if not file.filename.endswith('.pdf'):
        raise HTTPException(400, "åªæ”¯æ´PDFæª”æ¡ˆ")
    
    # 2. è¨ˆç®—æª”æ¡ˆé›œæ¹Š
    file_content = await file.read()
    file_hash = calculate_file_hash(file_content)
    
    # 3. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
    existing_paper = await db_service.find_paper_by_hash(db, file_hash)
    if existing_paper:
        # æª”æ¡ˆå·²å­˜åœ¨ï¼Œç›´æ¥æ¨™è¨˜ç‚ºå·²é¸å–
        await db_service.mark_paper_selected(db, existing_paper.id)
        return {
            "paper_id": existing_paper.id,
            "status": "exists",
            "message": "æª”æ¡ˆå·²å­˜åœ¨ï¼Œå·²è‡ªå‹•åŠ å…¥é¸å–æ¸…å–®"
        }
    
    # 4. å»ºç«‹æ–°è«–æ–‡è¨˜éŒ„
    paper_id = await db_service.create_paper(db, {
        "file_name": file.filename,
        "original_filename": file.filename,
        "file_size": len(file_content),
        "file_hash": file_hash,
        "processing_status": "uploaded"
    })
    
    # 5. æš«å­˜PDFæª”æ¡ˆ
    temp_file_path = await file_service.save_temp_file(paper_id, file_content)
    
    # 6. åŠ å…¥è™•ç†ä½‡åˆ—
    await queue_service.add_to_queue(db, paper_id, "grobid_processing")
    
    # 7. å•Ÿå‹•èƒŒæ™¯è™•ç†
    background_tasks.add_task(process_paper_pipeline, paper_id)
    
    return {
        "paper_id": paper_id,
        "status": "uploaded",
        "message": "æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼Œé–‹å§‹è™•ç†"
    }

# === æ‰¹æ¬¡è™•ç†æ ¸å¿ƒé‚è¼¯ ===
async def process_paper_pipeline(paper_id: str):
    """è«–æ–‡è™•ç†çš„å®Œæ•´æµç¨‹"""
    db = await get_async_db()
    
    try:
        # éšæ®µ1: æ›´æ–°ç‹€æ…‹ç‚ºè™•ç†ä¸­
        await db_service.update_paper_status(db, paper_id, "processing")
        await queue_service.update_queue_status(db, paper_id, "grobid_processing", "processing")
        
        # éšæ®µ2: Grobid TEIè™•ç†
        tei_result = await grobid_service.process_document(paper_id)
        
        # éšæ®µ3: å„²å­˜TEI XMLå’Œå…ƒæ•¸æ“š
        await db_service.save_tei_data(db, paper_id, {
            "tei_xml": tei_result.tei_xml,
            "tei_metadata": tei_result.metadata,
            "grobid_processed": True
        })
        
        # éšæ®µ4: è§£æä¸¦å„²å­˜ç« ç¯€
        sections = tei_result.sections
        for section in sections:
            section_id = await db_service.create_paper_section(db, {
                "paper_id": paper_id,
                "section_type": section.type,
                "page_num": section.page_start,
                "content": section.content,
                "section_order": section.order,
                "tei_coordinates": section.coordinates,
                "word_count": section.word_count
            })
        
        # éšæ®µ5: å¥å­åˆ‡åˆ†èˆ‡åˆ†æ
        await queue_service.update_queue_status(db, paper_id, "sentence_processing", "processing")
        
        total_sentences = 0
        processed_sentences = 0
        
        for section in sections:
            # å¥å­åˆ‡åˆ†
            sentences = await split_sentences_service.process(section.content)
            total_sentences += len(sentences)
            
            section_id = section.id  # å¾å‰é¢æ­¥é©Ÿå–å¾—
            
            # æ‰¹æ¬¡è™•ç†å¥å­ (æ¯æ¬¡è™•ç†10å¥ï¼Œé¿å…APIéè¼‰)
            for i in range(0, len(sentences), 10):
                batch = sentences[i:i+10]
                
                # ä¸¦è¡Œè™•ç†é€™æ‰¹å¥å­çš„OD/CDåˆ†æ
                tasks = []
                for j, sentence in enumerate(batch):
                    task = analyze_sentence_with_retry(sentence, paper_id, section_id, i+j)
                    tasks.append(task)
                
                # ç­‰å¾…é€™æ‰¹å®Œæˆ
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # å„²å­˜çµæœ
                for result in batch_results:
                    if not isinstance(result, Exception):
                        await db_service.create_sentence(db, result)
                        processed_sentences += 1
                
                # æ›´æ–°é€²åº¦
                progress = (processed_sentences / total_sentences) * 100
                await queue_service.update_processing_details(db, paper_id, {
                    "stage": "sentence_analysis",
                    "progress": progress,
                    "processed": processed_sentences,
                    "total": total_sentences
                })
                
                # é¿å…éå¿«è«‹æ±‚ï¼ŒçŸ­æš«å»¶é²
                await asyncio.sleep(0.1)
        
        # éšæ®µ6: æ¨™è¨˜å®Œæˆä¸¦æ¸…ç†æª”æ¡ˆ
        await db_service.update_paper_status(db, paper_id, "completed", {
            "sentences_processed": True,
            "processing_completed_at": datetime.utcnow()
        })
        
        # éšæ®µ7: åˆªé™¤è‡¨æ™‚PDFæª”æ¡ˆ
        await file_service.delete_temp_file(paper_id)
        await db_service.mark_pdf_deleted(db, paper_id)
        
        # éšæ®µ8: è‡ªå‹•åŠ å…¥é¸å–æ¸…å–®
        await db_service.mark_paper_selected(db, paper_id)
        
        await queue_service.mark_completed(db, paper_id)
        
    except Exception as e:
        await handle_processing_error(db, paper_id, str(e))

# === å¥å­åˆ†ææœå‹™ (åŠ å…¥é‡è©¦æ©Ÿåˆ¶) ===
async def analyze_sentence_with_retry(
    sentence: str, 
    paper_id: str, 
    section_id: str, 
    sentence_order: int,
    max_retries: int = 3
) -> dict:
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„å¥å­åˆ†æ"""
    
    for attempt in range(max_retries):
        try:
            # èª¿ç”¨N8N APIé€²è¡ŒOD/CDåˆ†æ
            analysis = await n8n_service.check_od_cd(sentence)
            
            return {
                "paper_id": paper_id,
                "section_id": section_id,
                "sentence_text": sentence,
                "sentence_order": sentence_order,
                "defining_type": analysis.defining_type.upper(),
                "analysis_reason": analysis.reason,
                "confidence_score": getattr(analysis, 'confidence', None),
                "word_count": len(sentence.split())
            }
            
        except Exception as e:
            if attempt == max_retries - 1:
                # æœ€å¾Œä¸€æ¬¡é‡è©¦ä»å¤±æ•—ï¼Œå„²å­˜ç‚ºUNKNOWN
                return {
                    "paper_id": paper_id,
                    "section_id": section_id,
                    "sentence_text": sentence,
                    "sentence_order": sentence_order,
                    "defining_type": "UNKNOWN",
                    "analysis_reason": f"Analysis failed after {max_retries} retries: {str(e)}",
                    "confidence_score": None,
                    "word_count": len(sentence.split())
                }
            
            # ç­‰å¾…å¾Œé‡è©¦ (æŒ‡æ•¸é€€é¿)
            await asyncio.sleep(2 ** attempt)

# === æŸ¥è©¢è™•ç†API ===
@app.post("/api/query/process")
async def process_query(
    query_data: QueryRequest,
    db: AsyncSession = Depends(get_db)
):
    """è™•ç†ä½¿ç”¨è€…æŸ¥è©¢ - çµ±ä¸€æ™ºèƒ½è·¯ç”±"""
    
    # 1. å–å¾—é¸ä¸­çš„è«–æ–‡
    selected_papers = await db_service.get_selected_papers(db)
    
    if not selected_papers:
        raise HTTPException(400, "è«‹å…ˆé¸æ“‡è¦åˆ†æçš„è«–æ–‡")
    
    # 2. çµ±ä¸€æŸ¥è©¢è™•ç† (ç„¡éœ€æ„åœ–åˆ†é¡)
    result = await unified_query_processor.process(
        query_data.query,
        [p.id for p in selected_papers],
        db
    )
    
    return result

# === è«–æ–‡sectionæ‘˜è¦API ===
@app.get("/api/papers/sections_summary")
async def get_papers_sections_summary(db: AsyncSession = Depends(get_db)):
    """å–å¾—æ‰€æœ‰é¸ä¸­è«–æ–‡çš„sectionæ‘˜è¦è³‡è¨Š"""
    selected_papers = await db_service.get_selected_papers(db)
    
    if not selected_papers:
        return {"papers": []}
    
    papers_with_sections = await db_service.get_papers_with_sections_summary(
        db, 
        [p.id for p in selected_papers]
    )
    
    return {"papers": papers_with_sections}

# === è«–æ–‡ç®¡ç†API ===
@app.get("/api/papers")
async def get_papers(db: AsyncSession = Depends(get_db)):
    """å–å¾—æ‰€æœ‰è«–æ–‡æ¸…å–®"""
    return await db_service.get_all_papers(db)

@app.post("/api/papers/{paper_id}/select")
async def toggle_paper_selection(
    paper_id: str,
    select_data: dict,
    db: AsyncSession = Depends(get_db)
):
    """åˆ‡æ›è«–æ–‡é¸å–ç‹€æ…‹"""
    is_selected = select_data.get("is_selected", True)
    await db_service.set_paper_selection(db, paper_id, is_selected)
    return {"success": True}

@app.get("/api/papers/selected")
async def get_selected_papers(db: AsyncSession = Depends(get_db)):
    """å–å¾—å·²é¸å–çš„è«–æ–‡æ¸…å–®"""
    return await db_service.get_selected_papers(db)

@app.post("/api/papers/select_all")
async def select_all_papers(db: AsyncSession = Depends(get_db)):
    """å…¨é¸æ‰€æœ‰è«–æ–‡"""
    await db_service.select_all_papers(db)
    return {"success": True}

@app.post("/api/papers/deselect_all")
async def deselect_all_papers(db: AsyncSession = Depends(get_db)):
    """å–æ¶ˆå…¨é¸"""
    await db_service.deselect_all_papers(db)
    return {"success": True}

# === è™•ç†ç‹€æ…‹ç›£æ§API ===
@app.get("/api/papers/{paper_id}/status")
async def get_processing_status(
    paper_id: str,
    db: AsyncSession = Depends(get_db)
):
    """å–å¾—è«–æ–‡è™•ç†ç‹€æ…‹"""
    paper = await db_service.get_paper_by_id(db, paper_id)
    queue_info = await db_service.get_processing_queue_info(db, paper_id)
    
    return {
        "paper_id": paper_id,
        "status": paper.processing_status,
        "progress": queue_info.get("progress", 0) if queue_info else 0,
        "current_stage": queue_info.get("stage") if queue_info else None,
        "error_message": paper.error_message,
        "can_retry": paper.processing_status == "error"
    }

@app.post("/api/papers/{paper_id}/retry")
async def retry_processing(
    paper_id: str,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
):
    """é‡è©¦å¤±æ•—çš„è™•ç†"""
    
    # é‡è¨­ç‹€æ…‹
    await db_service.reset_paper_for_retry(db, paper_id)
    
    # é‡æ–°é–‹å§‹è™•ç†
    background_tasks.add_task(process_paper_pipeline, paper_id)
    
    return {"success": True, "message": "å·²é‡æ–°é–‹å§‹è™•ç†"}

# === éŒ¯èª¤è™•ç† ===
async def handle_processing_error(db: AsyncSession, paper_id: str, error_message: str):
    """è™•ç†éŒ¯èª¤"""
    await db_service.update_paper_status(db, paper_id, "error", error_message)
    await queue_service.mark_failed(db, paper_id, error_message)
    
    # è¨˜éŒ„è©³ç´°éŒ¯èª¤æ—¥èªŒ
    logger.error(f"Paper {paper_id} processing failed: {error_message}")
```

## æª”æ¡ˆç”Ÿå‘½é€±æœŸç®¡ç†

### PDFæª”æ¡ˆè‡ªå‹•æ¸…ç†ç­–ç•¥
```python
# file_service.py - æª”æ¡ˆç®¡ç†æœå‹™
import os
import aiofiles
from pathlib import Path
import shutil

class FileService:
    def __init__(self):
        self.temp_dir = Path("./temp_files")
        self.temp_dir.mkdir(exist_ok=True)
    
    async def save_temp_file(self, paper_id: str, file_content: bytes) -> str:
        """æš«å­˜ä¸Šå‚³çš„PDFæª”æ¡ˆ"""
        file_path = self.temp_dir / f"{paper_id}.pdf"
        
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(file_content)
        
        return str(file_path)
    
    async def delete_temp_file(self, paper_id: str) -> bool:
        """åˆªé™¤æš«å­˜çš„PDFæª”æ¡ˆ"""
        file_path = self.temp_dir / f"{paper_id}.pdf"
        
        try:
            if file_path.exists():
                file_path.unlink()  # åˆªé™¤æª”æ¡ˆ
                return True
        except Exception as e:
            logger.error(f"Failed to delete temp file {file_path}: {e}")
            return False
        
        return False
    
    async def cleanup_old_temp_files(self, max_age_hours: int = 24):
        """æ¸…ç†è¶…éæŒ‡å®šæ™‚é–“çš„æš«å­˜æª”æ¡ˆ (å®šæœŸä»»å‹™)"""
        import time
        current_time = time.time()
        
        for file_path in self.temp_dir.glob("*.pdf"):
            file_age = current_time - file_path.stat().st_mtime
            if file_age > (max_age_hours * 3600):
                try:
                    file_path.unlink()
                    logger.info(f"Cleaned up old temp file: {file_path}")
                except Exception as e:
                    logger.error(f"Failed to cleanup {file_path}: {e}")

# å®šæœŸæ¸…ç†ä»»å‹™
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

@scheduler.scheduled_job('interval', hours=6)  # æ¯6å°æ™‚åŸ·è¡Œä¸€æ¬¡
async def cleanup_temp_files():
    """å®šæœŸæ¸…ç†æš«å­˜æª”æ¡ˆ"""
    file_service = FileService()
    await file_service.cleanup_old_temp_files(max_age_hours=24)

# åœ¨FastAPIå•Ÿå‹•æ™‚é–‹å§‹æ’ç¨‹
@app.on_event("startup")
async def startup_event():
    scheduler.start()

@app.on_event("shutdown")
async def shutdown_event():
    scheduler.shutdown()
```

## å–®ä¸€ä½¿ç”¨è€…æ¨¡å¼å¯¦ä½œ

### å‰ç«¯ç‹€æ…‹ç®¡ç†ç°¡åŒ–
```typescript
// ç”±æ–¼æ˜¯å–®ä¸€ä½¿ç”¨è€…æ¨¡å¼ï¼Œç°¡åŒ–ç‹€æ…‹ç®¡ç†
interface AppState {
  papers: Paper[];
  selectedPaperIds: Set<string>;  // æ”¹ç‚ºç°¡å–®çš„Set
  processingPapers: Map<string, ProcessingStatus>;
  
  // ç§»é™¤ä½¿ç”¨è€…ç›¸é—œç‹€æ…‹
  // æ‰€æœ‰æ“ä½œéƒ½åŸºæ–¼å…¨åŸŸç‹€æ…‹
}

// Zustand Store ç°¡åŒ–
const useAppStore = create<AppState>((set, get) => ({
  papers: [],
  selectedPaperIds: new Set(),
  processingPapers: new Map(),
  
  // è¼‰å…¥æ‰€æœ‰è«–æ–‡
  loadPapers: async () => {
    const papers = await paperService.getAllPapers();
    const selectedPapers = await paperService.getSelectedPapers();
    
    set({
      papers,
      selectedPaperIds: new Set(selectedPapers.map(p => p.id))
    });
  },
  
  // æ›´æ–°é¸å–ç‹€æ…‹ (æ”¯æ´å¤šclientåŒæ­¥)
  togglePaperSelection: async (paperId: string) => {
    const { selectedPaperIds } = get();
    const isCurrentlySelected = selectedPaperIds.has(paperId);
    
    // æ›´æ–°å¾Œç«¯ç‹€æ…‹
    await paperService.togglePaperSelection(paperId, !isCurrentlySelected);
    
    // æ›´æ–°æœ¬åœ°ç‹€æ…‹
    const newSelectedIds = new Set(selectedPaperIds);
    if (isCurrentlySelected) {
      newSelectedIds.delete(paperId);
    } else {
      newSelectedIds.add(paperId);
    }
    
    set({ selectedPaperIds: newSelectedIds });
    
    // é€šçŸ¥å…¶ä»–clientæ›´æ–° (å¯é¸: ä½¿ç”¨WebSocket)
    this.broadcastStateChange();
  },
  
  // è™•ç†é€²åº¦æ›´æ–°
  updateProcessingStatus: (paperId: string, status: ProcessingStatus) => {
    const { processingPapers } = get();
    const newProcessingPapers = new Map(processingPapers);
    newProcessingPapers.set(paperId, status);
    
    set({ processingPapers: newProcessingPapers });
  }
}));
```

## å¤šClientåŒæ­¥æ©Ÿåˆ¶ (å¯é¸å¯¦ä½œ)

```typescript
// ç°¡å–®çš„è¼ªè©¢åŒæ­¥æ©Ÿåˆ¶
class MultiClientSyncService {
  private syncInterval: NodeJS.Timeout | null = null;
  
  startSync() {
    // æ¯30ç§’åŒæ­¥ä¸€æ¬¡ç‹€æ…‹
    this.syncInterval = setInterval(async () => {
      try {
        await this.syncPaperSelections();
        await this.syncPaperList();
      } catch (error) {
        console.error('Sync failed:', error);
      }
    }, 30000);
  }
  
  stopSync() {
    if (this.syncInterval) {
      clearInterval(this.syncInterval);
    }
  }
  
  private async syncPaperSelections() {
    const currentSelected = useAppStore.getState().selectedPaperIds;
    const serverSelected = await paperService.getSelectedPapers();
    const serverSelectedIds = new Set(serverSelected.map(p => p.id));
    
    // å¦‚æœç‹€æ…‹ä¸åŒï¼Œæ›´æ–°æœ¬åœ°ç‹€æ…‹
    if (!this.setsEqual(currentSelected, serverSelectedIds)) {
      useAppStore.setState({ selectedPaperIds: serverSelectedIds });
    }
  }
  
  private async syncPaperList() {
    const papers = await paperService.getAllPapers();
    useAppStore.setState({ papers });
  }
  
  private setsEqual(set1: Set<string>, set2: Set<string>): boolean {
    return set1.size === set2.size && [...set1].every(x => set2.has(x));
  }
}

// åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚é–‹å§‹åŒæ­¥
const syncService = new MultiClientSyncService();

export function useMultiClientSync() {
  useEffect(() => {
    syncService.startSync();
    return () => syncService.stopSync();
  }, []);
}
```

## ç³»çµ±ç‰¹è‰²æ‘˜è¦

### âœ… **è³‡æ–™åº«å¢å¼·**
- **TEI XMLå„²å­˜**ï¼šå®Œæ•´ä¿å­˜Grobidè¼¸å‡ºï¼Œä¾¿æ–¼æœªä¾†åŠŸèƒ½æ“´å±•
- **æª”æ¡ˆå»é‡**ï¼šåŸºæ–¼é›œæ¹Šå€¼çš„æª”æ¡ˆå»é‡æ©Ÿåˆ¶
- **ç´¢å¼•å„ªåŒ–**ï¼šæŸ¥è©¢æ•ˆèƒ½å„ªåŒ–çš„è³‡æ–™åº«ç´¢å¼•

### âœ… **æª”æ¡ˆç®¡ç†å„ªåŒ–**
- **è‡ªå‹•æ¸…ç†**ï¼šè™•ç†å®Œæˆå¾Œè‡ªå‹•åˆªé™¤PDFæª”æ¡ˆ
- **ç”Ÿå‘½é€±æœŸç®¡ç†**ï¼šå®Œæ•´çš„æª”æ¡ˆç”Ÿå‘½é€±æœŸæ§åˆ¶
- **å®šæœŸæ¸…ç†**ï¼šå®šæ™‚æ¸…ç†éæœŸæš«å­˜æª”æ¡ˆ

### âœ… **å–®ä¸€ä½¿ç”¨è€…æ¨¡å¼**
- **ç°¡åŒ–æ¶æ§‹**ï¼šç§»é™¤è¤‡é›œçš„ä½¿ç”¨è€…ç®¡ç†
- **å¤šClientæ”¯æ´**ï¼šæ”¯æ´å¤šå€‹ç€è¦½å™¨è¦–çª—åŒæ™‚æ“ä½œ
- **ç‹€æ…‹åŒæ­¥**ï¼šè‡ªå‹•åŒæ­¥å„Clientçš„ç‹€æ…‹

### âœ… **FastAPIæ‰¹æ¬¡è™•ç†**
- **å®Œæ•´ä½‡åˆ—ç®¡ç†**ï¼šå®Œå–„çš„è™•ç†ä½‡åˆ—å’Œç‹€æ…‹è¿½è¹¤
- **éŒ¯èª¤é‡è©¦**ï¼šæ™ºèƒ½é‡è©¦æ©Ÿåˆ¶å’ŒéŒ¯èª¤è™•ç†
- **é€²åº¦ç›£æ§**ï¼šå¯¦æ™‚é€²åº¦æ›´æ–°å’Œç‹€æ…‹åŒæ­¥

### âœ… **æ¶æ§‹çµ±ä¸€**
- **APIçµ±ä¸€**ï¼šæ‰€æœ‰è³‡æ–™åº«æ“ä½œçµ±ä¸€é€éFastAPI
- **æ‰¹æ¬¡è™•ç†**ï¼šé«˜æ•ˆçš„æ‰¹æ¬¡å¥å­åˆ†æ
- **TEIæ•´åˆ**ï¼šå®Œæ•´çš„Grobid TEIæ•´åˆ

é€™å€‹å¢å¼·å‹ç³»çµ±æä¾›äº†å®Œæ•´çš„å¤šæª”æ¡ˆè«–æ–‡åˆ†æèƒ½åŠ›ï¼Œæ”¯æ´TEIå„²å­˜ã€è‡ªå‹•æª”æ¡ˆæ¸…ç†ã€æ‰¹æ¬¡è™•ç†ã€éŒ¯èª¤é‡è©¦ã€é€²åº¦è¿½è¹¤ç­‰åŠŸèƒ½ï¼Œå®Œå…¨æ»¿è¶³æ‚¨çš„æœ€ä½ç•¢æ¥­è¦æ±‚ã€‚æ¥ä¸‹ä¾†æˆ‘æœƒç‚ºæ‚¨åˆ¶å®šè©³ç´°çš„é–‹ç™¼backlogã€‚ 

## ç³»çµ±ç°¡åŒ–èˆ‡å„ªåŒ–ç¸½çµ

### âœ… **å·¥ä½œæµç¨‹å„ªåŒ–å°æ¯”**

#### åŸè¨­è¨ˆ (è¤‡é›œè·¯å¾‘)
```
æŸ¥è©¢ â†’ æ„åœ–åˆ†é¡ â†’ è·¯å¾‘A(å®šç¾©) / è·¯å¾‘B(å…§å®¹) â†’ ä¸åŒè™•ç†é‚è¼¯ â†’ æ•´åˆçµæœ
```

#### æ–°è¨­è¨ˆ (çµ±ä¸€æ™ºèƒ½è·¯å¾‘)
```
æŸ¥è©¢ â†’ æä¾›å…¨éƒ¨papersçš„sectionsæ‘˜è¦ â†’ LLMæ™ºèƒ½é¸æ“‡ â†’ çµ±ä¸€å…§å®¹åˆ†æ â†’ æ•´åˆçµæœ
```

### âœ… **æ ¸å¿ƒæ”¹é€²é»**

1. **âŒ ç§»é™¤è¤‡é›œæ„åœ–åˆ†é¡**
   - åŸæœ¬éœ€è¦å…ˆåˆ¤æ–·æ˜¯å¦ç‚ºã€Œå®šç¾©ç›¸é—œæŸ¥è©¢ã€
   - åˆ†é¡éŒ¯èª¤æœƒå°è‡´å¾ŒçºŒè™•ç†ä¸ç•¶
   - **æ”¹ç‚º**ï¼šç›´æ¥è®“LLMæ ¹æ“šqueryå’Œsectionè³‡è¨Šæ™ºèƒ½é¸æ“‡

2. **âœ… æä¾›å®Œæ•´sectionè³‡è¨Š**
   - æ¯å€‹paperçš„æ‰€æœ‰sectioné¡å‹ã€é æ•¸ã€å­—æ•¸
   - ç°¡çŸ­å…§å®¹é è¦½ (å‰100å­—)
   - OD/CDå¥å­çµ±è¨ˆ (od_count, cd_count)
   - **è®“LLMæœ‰è¶³å¤ è³‡è¨Šåšå‡ºæœ€ä½³é¸æ“‡**

3. **âœ… éˆæ´»çš„å…§å®¹æå–ç­–ç•¥**
   - `definitions`ï¼šæå–OD/CDå¥å­
   - `full_section`ï¼šæå–å®Œæ•´ç« ç¯€å…§å®¹
   - `key_sentences`ï¼šåŸºæ–¼é—œéµè©çš„å¥å­æœå°‹
   - **LLMæ ¹æ“šæŸ¥è©¢æ€§è³ªæ±ºå®šæœ€é©åˆçš„ç­–ç•¥**

4. **âœ… çµ±ä¸€çš„åˆ†æAPI**
   - å–®ä¸€ `unified_content_analysis` API
   - æ”¯æ´æ‰€æœ‰é¡å‹çš„åˆ†æéœ€æ±‚
   - æ¸›å°‘APIç¶­è­·è¤‡é›œåº¦

### âœ… **N8N API ç°¡åŒ–**

#### åŸè¨­è¨ˆéœ€è¦çš„APIs
- âœ… `keywords_extraction` (ä¿ç•™)
- âœ… `check_od_cd` (ä¿ç•™)  
- âŒ `query_intent_classification` (ç§»é™¤)
- âŒ `section_suggestion` (ç§»é™¤)
- âŒ `enhanced_organize_response` (ä¿ç•™ç”¨æ–¼å‘å¾Œç›¸å®¹)
- âŒ `multi_paper_content_analysis` (ç§»é™¤)

#### æ–°è¨­è¨ˆåªéœ€è¦çš„APIs
- âœ… `keywords_extraction` (ç¾æœ‰)
- âœ… `check_od_cd` (ç¾æœ‰)
- ğŸ†• `intelligent_section_selection` (æ–°å¢)
- ğŸ†• `unified_content_analysis` (æ–°å¢)

**APIæ•¸é‡å¾6å€‹æ¸›å°‘ç‚º4å€‹ï¼Œç¶­è­·æˆæœ¬é™ä½33%**

### âœ… **å¯¦éš›æŸ¥è©¢ç¯„ä¾‹å°æ¯”**

#### ç¯„ä¾‹æŸ¥è©¢ï¼šã€Œå¦‚ä½•æ¸¬é‡adaptive expertiseçš„å­¸ç¿’æˆæ•ˆï¼Ÿã€

**åŸè¨­è¨ˆæµç¨‹ï¼š**
1. æ„åœ–åˆ†æ â†’ åˆ¤æ–·ç‚ºã€Œæ¸¬é‡æ–¹æ³•ç›¸é—œã€(éå®šç¾©)
2. ç« ç¯€å»ºè­° â†’ å»ºè­°æŸ¥æ‰¾ `["method", "results"]`
3. æå–å…§å®¹ â†’ å¾æ‰€æœ‰papersçš„method/resultsç« ç¯€æå–
4. å…§å®¹åˆ†æ â†’ èª¿ç”¨ `multi_paper_content_analysis`

**æ–°è¨­è¨ˆæµç¨‹ï¼š**
1. æä¾›sectionsæ‘˜è¦ â†’ åŒ…å«æ‰€æœ‰papersçš„å®Œæ•´sectionè³‡è¨Š
2. LLMæ™ºèƒ½é¸æ“‡ â†’ å¯èƒ½é¸æ“‡ï¼š
   - paper1çš„method section (focus_type: key_sentences, keywords: [measurement, assessment])
   - paper2çš„results section (focus_type: full_section)
   - paper3çš„introduction section (focus_type: definitions - å¦‚æœåŒ…å«ç›¸é—œå®šç¾©)
3. çµ±ä¸€åˆ†æ â†’ ä¸€æ¬¡APIèª¿ç”¨è™•ç†æ‰€æœ‰å…§å®¹

**å„ªå‹¢ï¼šLLMå¯ä»¥è·¨sectioné¡å‹æ™ºèƒ½é¸æ“‡ï¼Œä¸å—é è¨­è¦å‰‡é™åˆ¶**

### âœ… **å‰ç«¯å¯¦ä½œç°¡åŒ–**

```typescript
// åŸè¨­è¨ˆ - è¤‡é›œçš„æ¢ä»¶è™•ç†
const processQuery = async (query: string) => {
  const intent = await n8nAPI.classifyIntent(query);
  
  if (intent.is_definition_related) {
    const keywords = await n8nAPI.extractKeywords(query);
    const definitions = await searchDefinitions(keywords);
    const result = await n8nAPI.enhancedOrganizeResponse({query, papers: definitions});
  } else {
    const sections = await n8nAPI.suggestSections(query);
    const content = await extractSectionContent(sections);
    const result = await n8nAPI.multiPaperContentAnalysis({query, papers: content});
  }
};

// æ–°è¨­è¨ˆ - çµ±ä¸€ç°¡æ½”æµç¨‹
const processQuery = async (query: string) => {
  const papersWithSections = await api.getPapersSectionsSummary();
  const sectionSelection = await n8nAPI.intelligentSectionSelection({
    query, 
    available_papers: papersWithSections
  });
  const selectedContent = await extractSelectedContent(sectionSelection.selected_sections);
  const result = await n8nAPI.unifiedContentAnalysis({
    query, 
    selected_content: selectedContent,
    analysis_focus: sectionSelection.analysis_focus
  });
};
```

### âœ… **ç³»çµ±ç¶­è­·å„ªå‹¢**

1. **é™ä½LLM Tokenæ¶ˆè€—**ï¼š
   - æ¸›å°‘å¤šæ¬¡æ„åœ–åˆ†æèª¿ç”¨
   - å–®æ¬¡èª¿ç”¨åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡è³‡è¨Š

2. **æé«˜å›æ‡‰æº–ç¢ºæ€§**ï¼š
   - LLMèƒ½çœ‹åˆ°å®Œæ•´çš„sectioné¸æ“‡ç©ºé–“
   - é¿å…é è¨­åˆ†é¡çš„åè¦‹

3. **å¢å¼·æ“´å±•æ€§**ï¼š
   - æ–°å¢è«–æ–‡ç« ç¯€é¡å‹æ™‚ï¼Œç„¡éœ€ä¿®æ”¹åˆ†é¡é‚è¼¯
   - LLMè‡ªç„¶é©æ‡‰æ–°çš„sectionçµæ§‹

4. **ç°¡åŒ–éŒ¯èª¤è™•ç†**ï¼š
   - æ¸›å°‘å¤šéšæ®µè™•ç†çš„éŒ¯èª¤é»
   - çµ±ä¸€çš„APIéŒ¯èª¤è™•ç†æ©Ÿåˆ¶

é€™å€‹ç°¡åŒ–è¨­è¨ˆå®Œç¾ç¬¦åˆæ‚¨çš„å»ºè­°ï¼Œè®“LLMåšå®ƒæœ€æ“…é•·çš„äº‹ï¼š**åŸºæ–¼è±å¯Œçš„ä¸Šä¸‹æ–‡è³‡è¨Šåšå‡ºæ™ºèƒ½æ±ºç­–**ï¼Œè€Œä¸æ˜¯ä¾è³´é è¨­çš„åˆ†é¡è¦å‰‡ã€‚ 