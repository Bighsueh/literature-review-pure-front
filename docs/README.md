# è«–æ–‡åˆ†æç³»çµ±æ–‡æª”

## ç³»çµ±æ¦‚è¿°

è«–æ–‡åˆ†æç³»çµ±æ˜¯ä¸€å€‹åŸºæ–¼ AI çš„å­¸è¡“è«–æ–‡è‡ªå‹•åˆ†æå¹³å°ï¼Œèƒ½å¤ è‡ªå‹•æå–å’Œåˆ†æè«–æ–‡ä¸­çš„ç ”ç©¶ç›®æ¨™å®šç¾©ï¼ˆObjective Definition, ODï¼‰ã€è³‡æ–™é›†å®šç¾©ï¼ˆDataset Definition, CDï¼‰å’Œè²¢ç»å®šç¾©ï¼ˆContribution Definitionï¼‰ã€‚

### ä¸»è¦åŠŸèƒ½

- **PDF è«–æ–‡ä¸Šå‚³èˆ‡è§£æ**: æ”¯æ´ PDF æ ¼å¼è«–æ–‡ä¸Šå‚³ï¼Œä½¿ç”¨ Grobid é€²è¡Œçµæ§‹åŒ–è§£æ
- **æ™ºèƒ½ç« ç¯€åˆ†æ**: è‡ªå‹•è­˜åˆ¥è«–æ–‡ç« ç¯€ï¼ˆæ‘˜è¦ã€ä»‹ç´¹ã€æ–¹æ³•è«–ã€çµæœã€çµè«–ç­‰ï¼‰
- **å¥å­ç´šåˆ¥åˆ†æ**: æå–ä¸¦åˆ†ææ¯å€‹å¥å­ï¼Œè­˜åˆ¥å…¶ä¸­çš„é—œéµå®šç¾©
- **AI é©…å‹•æª¢æ¸¬**: ä½¿ç”¨å¤§èªè¨€æ¨¡å‹æª¢æ¸¬ ODã€CD å’Œè²¢ç»å®šç¾©
- **å…¨æ–‡æœç´¢**: æ”¯æ´è·¨è«–æ–‡çš„é—œéµè©æœç´¢å’Œèªç¾©æœç´¢
- **çµ±è¨ˆåˆ†æ**: æä¾›è©³ç´°çš„çµ±è¨ˆè³‡è¨Šå’Œåˆ†æå ±å‘Š

### æŠ€è¡“æ¶æ§‹

- **å¾Œç«¯**: FastAPI (Python)
- **è³‡æ–™åº«**: PostgreSQL 15.13
- **å‰ç«¯**: React
- **å®¹å™¨åŒ–**: Docker & Docker Compose
- **PDF è™•ç†**: Grobid TEI è§£æ
- **AI æ¨¡å‹**: å¤§èªè¨€æ¨¡å‹ API æ•´åˆ
- **å¿«å–**: Redis

## æ–‡æª”å°èˆª

### ğŸ“‹ æ ¸å¿ƒæ–‡æª”

| æ–‡æª” | æè¿° | é©ç”¨å°è±¡ |
|------|------|----------|
| [è³‡æ–™åº« Schema](database_schema.md) | å®Œæ•´çš„è³‡æ–™åº«çµæ§‹æ–‡æª”ï¼ŒåŒ…å«æ‰€æœ‰è¡¨æ ¼ã€æ¬„ä½ã€é—œä¿‚å’Œç´„æŸ | é–‹ç™¼è€…ã€DBA |
| [è³‡æ–™åº« ER åœ–](database_er_diagram.md) | å¯¦é«”é—œä¿‚åœ–å’Œè³‡æ–™åº«è¨­è¨ˆèªªæ˜ | é–‹ç™¼è€…ã€æ¶æ§‹å¸« |
| [API æ–‡æª”](api_documentation.md) | å®Œæ•´çš„ REST API æ–‡æª”ï¼ŒåŒ…å«æ‰€æœ‰ç«¯é»å’Œä½¿ç”¨ç¯„ä¾‹ | å‰ç«¯é–‹ç™¼è€…ã€API ä½¿ç”¨è€… |

### ğŸ—ï¸ ç³»çµ±æ¶æ§‹

```mermaid
graph TB
    subgraph "å‰ç«¯å±¤"
        A[React å‰ç«¯]
    end
    
    subgraph "API å±¤"
        B[FastAPI å¾Œç«¯]
        C[REST API]
    end
    
    subgraph "æœå‹™å±¤"
        D[è«–æ–‡è™•ç†æœå‹™]
        E[AI åˆ†ææœå‹™]
        F[æœç´¢æœå‹™]
    end
    
    subgraph "è³‡æ–™å±¤"
        G[PostgreSQL]
        H[Redis å¿«å–]
    end
    
    subgraph "å¤–éƒ¨æœå‹™"
        I[Grobid TEI è§£æ]
        J[å¤§èªè¨€æ¨¡å‹ API]
    end
    
    A --> B
    B --> C
    C --> D
    C --> E
    C --> F
    D --> I
    E --> J
    D --> G
    E --> G
    F --> G
    F --> H
```

### ğŸ“Š è³‡æ–™æµç¨‹

```mermaid
sequenceDiagram
    participant U as ä½¿ç”¨è€…
    participant F as å‰ç«¯
    participant A as API
    participant P as è™•ç†æœå‹™
    participant G as Grobid
    participant AI as AI æœå‹™
    participant DB as è³‡æ–™åº«
    
    U->>F: ä¸Šå‚³ PDF
    F->>A: POST /upload/
    A->>P: å•Ÿå‹•è™•ç†æµç¨‹
    A->>U: è¿”å› paper_id
    
    P->>G: TEI è§£æ
    G->>P: è¿”å›çµæ§‹åŒ–å…§å®¹
    P->>DB: å„²å­˜ç« ç¯€è³‡æ–™
    
    P->>AI: OD/CD æª¢æ¸¬
    AI->>P: è¿”å›åˆ†æçµæœ
    P->>DB: å„²å­˜å¥å­åˆ†æ
    
    P->>DB: æ›´æ–°è™•ç†ç‹€æ…‹
    
    U->>F: æŸ¥è©¢çµæœ
    F->>A: GET /papers/{id}
    A->>DB: æŸ¥è©¢è³‡æ–™
    DB->>A: è¿”å›çµæœ
    A->>F: è¿”å›è«–æ–‡è³‡æ–™
    F->>U: é¡¯ç¤ºåˆ†æçµæœ
```

## å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒè¦æ±‚

- Docker & Docker Compose
- Python 3.9+
- Node.js 16+
- PostgreSQL 15+

### 2. å•Ÿå‹•ç³»çµ±

```bash
# å…‹éš†å°ˆæ¡ˆ
git clone <repository-url>
cd pure_front

# å•Ÿå‹•æ‰€æœ‰æœå‹™
docker-compose up -d

# æª¢æŸ¥æœå‹™ç‹€æ…‹
docker-compose ps
```

### 3. é©—è­‰å®‰è£

```bash
# æª¢æŸ¥ API å¥åº·ç‹€æ…‹
curl http://localhost:8000/health

# æª¢æŸ¥å‰ç«¯
open http://localhost:3000

# æª¢æŸ¥è³‡æ–™åº«é€£æ¥
docker-compose exec paper_analysis_db psql -U postgres -d paper_analysis -c "\dt"
```

### 4. ä¸Šå‚³ç¬¬ä¸€å€‹è«–æ–‡

```bash
# ä½¿ç”¨ curl ä¸Šå‚³ PDF
curl -X POST "http://localhost:8000/api/upload/" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@your_paper.pdf"
```

## é–‹ç™¼æŒ‡å—

### è³‡æ–™åº«æ“ä½œ

```sql
-- æŸ¥çœ‹è«–æ–‡è™•ç†ç‹€æ…‹
SELECT id, file_name, processing_status, 
       grobid_processed, sentences_processed, od_cd_processed
FROM papers 
ORDER BY created_at DESC;

-- æŸ¥çœ‹å¥å­åˆ†æçµæœ
SELECT p.file_name, s.content, s.has_objective, s.has_dataset, s.has_contribution
FROM sentences s
JOIN papers p ON s.paper_id = p.id
WHERE s.has_objective = true OR s.has_dataset = true OR s.has_contribution = true;
```

### API ä½¿ç”¨ç¯„ä¾‹

```python
import requests

# ä¸Šå‚³è«–æ–‡
with open('paper.pdf', 'rb') as f:
    response = requests.post('http://localhost:8000/api/upload/', 
                           files={'file': f})
paper_id = response.json()['paper_id']

# æŸ¥è©¢è™•ç†ç‹€æ…‹
status = requests.get(f'http://localhost:8000/api/papers/{paper_id}/status')
print(status.json())

# æœç´¢å¥å­
results = requests.get('http://localhost:8000/api/sentences/search', 
                      params={'q': 'machine learning'})
print(f"æ‰¾åˆ° {results.json()['total']} å€‹ç›¸é—œå¥å­")
```

## ç³»çµ±ç›£æ§

### å®¹å™¨ç‹€æ…‹ç›£æ§

```bash
# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨ç‹€æ…‹
docker-compose ps

# æŸ¥çœ‹å®¹å™¨æ—¥èªŒ
docker-compose logs -f paper_analysis_backend
docker-compose logs -f paper_analysis_db

# æŸ¥çœ‹è³‡æºä½¿ç”¨æƒ…æ³
docker stats
```

### è³‡æ–™åº«ç›£æ§

```sql
-- æŸ¥çœ‹è¡¨æ ¼å¤§å°
SELECT 
    tablename,
    pg_size_pretty(pg_total_relation_size(tablename::regclass)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(tablename::regclass) DESC;

-- æŸ¥çœ‹è™•ç†çµ±è¨ˆ
SELECT 
    processing_status,
    COUNT(*) as count,
    AVG(EXTRACT(EPOCH FROM (processing_completed_at - upload_timestamp))) as avg_processing_time
FROM papers 
WHERE processing_completed_at IS NOT NULL
GROUP BY processing_status;
```

### API æ•ˆèƒ½ç›£æ§

```bash
# æ¸¬è©¦ API éŸ¿æ‡‰æ™‚é–“
curl -w "@curl-format.txt" -o /dev/null -s "http://localhost:8000/api/papers/"

# æ‰¹é‡æ¸¬è©¦
for i in {1..10}; do
    curl -w "%{time_total}\n" -o /dev/null -s "http://localhost:8000/api/papers/"
done
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **å®¹å™¨å•Ÿå‹•å¤±æ•—**
   ```bash
   # æª¢æŸ¥ç«¯å£å ç”¨
   lsof -i :8000
   lsof -i :3000
   lsof -i :5432
   
   # é‡æ–°æ§‹å»ºå®¹å™¨
   docker-compose down
   docker-compose build --no-cache
   docker-compose up -d
   ```

2. **è³‡æ–™åº«é€£æ¥å•é¡Œ**
   ```bash
   # æª¢æŸ¥è³‡æ–™åº«å®¹å™¨
   docker-compose logs paper_analysis_db
   
   # æ‰‹å‹•é€£æ¥æ¸¬è©¦
   docker-compose exec paper_analysis_db psql -U postgres -d paper_analysis
   ```

3. **è™•ç†å¡ä½**
   ```sql
   -- æŸ¥çœ‹è™•ç†ä½‡åˆ—
   SELECT * FROM processing_queue WHERE status = 'processing';
   
   -- é‡ç½®å¡ä½çš„ä»»å‹™
   UPDATE processing_queue 
   SET status = 'failed', error_message = 'Manual reset'
   WHERE status = 'processing' 
   AND started_at < NOW() - INTERVAL '1 hour';
   ```

### æ—¥èªŒåˆ†æ

```bash
# æŸ¥çœ‹å¾Œç«¯æ—¥èªŒ
docker-compose logs -f --tail=100 paper_analysis_backend

# æŸ¥çœ‹ç‰¹å®šéŒ¯èª¤
docker-compose logs paper_analysis_backend | grep ERROR

# æŸ¥çœ‹è™•ç†é€²åº¦
docker-compose logs paper_analysis_backend | grep "Processing"
```

## ç¶­è­·æŒ‡å—

### å®šæœŸç¶­è­·ä»»å‹™

1. **è³‡æ–™åº«æ¸…ç†**
   ```sql
   -- æ¸…ç†è¶…é 30 å¤©çš„éŒ¯èª¤è¨˜éŒ„
   DELETE FROM processing_queue 
   WHERE status = 'failed' 
   AND created_at < NOW() - INTERVAL '30 days';
   ```

2. **æ—¥èªŒè¼ªè½‰**
   ```bash
   # æ¸…ç† Docker æ—¥èªŒ
   docker system prune -f
   docker volume prune -f
   ```

3. **å‚™ä»½è³‡æ–™åº«**
   ```bash
   # å‰µå»ºå‚™ä»½
   docker-compose exec paper_analysis_db pg_dump -U postgres paper_analysis > backup_$(date +%Y%m%d).sql
   
   # é‚„åŸå‚™ä»½
   docker-compose exec -T paper_analysis_db psql -U postgres paper_analysis < backup_20250114.sql
   ```

### æ•ˆèƒ½å„ªåŒ–

1. **è³‡æ–™åº«ç´¢å¼•å„ªåŒ–**
   ```sql
   -- åˆ†ææŸ¥è©¢æ•ˆèƒ½
   EXPLAIN ANALYZE SELECT * FROM sentences WHERE has_objective = true;
   
   -- é‡å»ºç´¢å¼•
   REINDEX INDEX idx_sentences_has_objective;
   ```

2. **å¿«å–ç­–ç•¥**
   ```bash
   # æª¢æŸ¥ Redis ä½¿ç”¨æƒ…æ³
   docker-compose exec pdf-splitter-redis redis-cli info memory
   
   # æ¸…ç†å¿«å–
   docker-compose exec pdf-splitter-redis redis-cli flushall
   ```

## ç‰ˆæœ¬è³‡è¨Š

- **ç³»çµ±ç‰ˆæœ¬**: 1.0.0
- **è³‡æ–™åº«ç‰ˆæœ¬**: PostgreSQL 15.13
- **API ç‰ˆæœ¬**: v1
- **æœ€å¾Œæ›´æ–°**: 2025-01-14

## è²¢ç»æŒ‡å—

1. Fork å°ˆæ¡ˆ
2. å‰µå»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤è®Šæ›´ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. é–‹å•Ÿ Pull Request

## æˆæ¬Š

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ã€‚è©³è¦‹ [LICENSE](../LICENSE) æª”æ¡ˆã€‚

## è¯çµ¡è³‡è¨Š

- **å°ˆæ¡ˆç¶­è­·è€…**: [ç¶­è­·è€…å§“å]
- **Email**: [email@example.com]
- **å•é¡Œå›å ±**: [GitHub Issues](https://github.com/your-repo/issues)

---

ğŸ“š **æ›´å¤šæ–‡æª”**: 
- [è³‡æ–™åº« Schema è©³ç´°èªªæ˜](database_schema.md)
- [API å®Œæ•´æ–‡æª”](api_documentation.md)
- [è³‡æ–™åº« ER åœ–](database_er_diagram.md) 