"""
è³‡æ–™åº«é€£ç·šç®¡ç†æ¨¡çµ„
æä¾›PostgreSQLé€£ç·šæ± å’Œç•°æ­¥è³‡æ–™åº«æ“ä½œ
"""

import os
import asyncio
from typing import Optional, AsyncGenerator
from sqlalchemy import create_engine, text
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.pool import NullPool
import asyncpg
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# SQLAlchemy Base
Base = declarative_base()

class DatabaseManager:
    def __init__(self):
        self.database_url = self._get_database_url()
        self.async_database_url = self._get_async_database_url()
        self.engine = None
        self.async_engine = None
        self.async_session_maker = None
        self.session_maker = None
        
    def _get_database_url(self) -> str:
        """å–å¾—è³‡æ–™åº«é€£ç·šURL"""
        host = os.getenv("POSTGRES_HOST", "localhost")
        port = os.getenv("POSTGRES_PORT", "5432")
        database = os.getenv("POSTGRES_DB", "paper_analysis")
        username = os.getenv("POSTGRES_USER", "postgres")
        password = os.getenv("POSTGRES_PASSWORD", "password")
        
        return f"postgresql://{username}:{password}@{host}:{port}/{database}"
    
    def _get_async_database_url(self) -> str:
        """å–å¾—ç•°æ­¥è³‡æ–™åº«é€£ç·šURL"""
        return self.database_url.replace("postgresql://", "postgresql+asyncpg://")
    
    async def initialize(self):
        """åˆå§‹åŒ–è³‡æ–™åº«é€£ç·š"""
        try:
            # å»ºç«‹ç•°æ­¥å¼•æ“
            self.async_engine = create_async_engine(
                self.async_database_url,
                echo=False,  # ç”Ÿç”¢ç’°å¢ƒè¨­ç‚ºFalse
                pool_pre_ping=True,
                pool_recycle=3600,
                pool_size=10,
                max_overflow=20,
                poolclass=NullPool if os.getenv("TESTING") else None
            )
            
            # å»ºç«‹ç•°æ­¥session maker
            self.async_session_maker = async_sessionmaker(
                self.async_engine,
                class_=AsyncSession,
                expire_on_commit=False
            )
            
            # å»ºç«‹åŒæ­¥å¼•æ“ï¼ˆç”¨æ–¼åˆå§‹åŒ–ï¼‰
            self.engine = create_engine(
                self.database_url,
                pool_pre_ping=True,
                pool_recycle=3600
            )
            
            self.session_maker = sessionmaker(bind=self.engine)
            
            logger.info("è³‡æ–™åº«é€£ç·šåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"è³‡æ–™åº«é€£ç·šåˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def create_tables(self):
        """å»ºç«‹è³‡æ–™åº«è¡¨æ ¼ï¼ˆä½¿ç”¨Alembic migrationï¼‰"""
        logger.info("ğŸš¨ CREATE_TABLES æ–¹æ³•è¢«èª¿ç”¨ï¼é–‹å§‹åŸ·è¡Œ...")
        try:
            logger.info("ğŸ“‹ åŸ·è¡ŒAlembicé·ç§»...")
            
            # ä½¿ç”¨Alembicé…ç½®åŸ·è¡Œé·ç§»
            from alembic.config import Config
            from alembic import command
            import tempfile
            import os
            
            # å–å¾—migrationç›®éŒ„è·¯å¾‘
            backend_dir = os.path.dirname(os.path.dirname(__file__))
            migrations_dir = os.path.join(backend_dir, "migrations")
            alembic_ini_path = os.path.join(backend_dir, "alembic.ini")
            
            logger.info(f"ğŸ” æª¢æŸ¥Alembicè¨­å®šæª”æ¡ˆ...")
            logger.info(f"  - backend_dir: {backend_dir}")
            logger.info(f"  - migrations_dir: {migrations_dir}")
            logger.info(f"  - alembic_ini_path: {alembic_ini_path}")
            
            if not os.path.exists(alembic_ini_path):
                logger.error(f"æ‰¾ä¸åˆ°alembic.iniæª”æ¡ˆ: {alembic_ini_path}")
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°alembic.iniæª”æ¡ˆ: {alembic_ini_path}")
            
            if not os.path.exists(migrations_dir):
                logger.error(f"æ‰¾ä¸åˆ°migrationsç›®éŒ„: {migrations_dir}")
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°migrationsç›®éŒ„: {migrations_dir}")
            
            # å»ºç«‹Alembicé…ç½®
            logger.info("ğŸ”§ å»ºç«‹Alembicé…ç½®...")
            alembic_cfg = Config(alembic_ini_path)
            logger.info(f"ğŸ“ è¨­å®šè³‡æ–™åº«URL: {self.database_url}")
            alembic_cfg.set_main_option("sqlalchemy.url", self.database_url)
            
            # ç¢ºä¿è³‡æ–™åº«æœ‰alembic_versionè¡¨ï¼Œå¦‚æœæ²’æœ‰å‰‡å»ºç«‹
            try:
                logger.info("ğŸ” æª¢æŸ¥migrationç‹€æ…‹...")
                # æª¢æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–alembic_versionè¡¨
                from alembic.migration import MigrationContext
                from alembic.operations import Operations
                
                with self.engine.connect() as connection:
                    logger.info("âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸï¼Œå»ºç«‹migration context...")
                    context = MigrationContext.configure(connection)
                    
                    # æª¢æŸ¥æ˜¯å¦å·²æœ‰migrationè¨˜éŒ„
                    current_rev = context.get_current_revision()
                    logger.info(f"ğŸ“Š ç›®å‰migrationç‰ˆæœ¬: {current_rev}")
                    
                    if current_rev is None:
                        logger.info("ï¿½ï¿½ åˆå§‹åŒ–Alembicç‰ˆæœ¬æ§åˆ¶...")
                        # æ¨™è¨˜ç‚ºå·²åŸ·è¡Œæœ€æ–°migration
                        command.stamp(alembic_cfg, "head")
                        logger.info("âœ… Alembicç‰ˆæœ¬æ§åˆ¶åˆå§‹åŒ–å®Œæˆ")
                    else:
                        logger.info(f"ğŸ“‹ ç™¼ç¾ç¾æœ‰migrationç‰ˆæœ¬: {current_rev}")
                        
                    # åŸ·è¡Œmigrationåˆ°æœ€æ–°ç‰ˆæœ¬
                    logger.info("â¬†ï¸ åŸ·è¡Œmigrationåˆ°æœ€æ–°ç‰ˆæœ¬...")
                    command.upgrade(alembic_cfg, "head")
                    logger.info("âœ… MigrationåŸ·è¡Œå®Œæˆ")
                    
            except Exception as migration_error:
                logger.error(f"âŒ Alembicé·ç§»å¤±æ•—: {migration_error}")
                logger.error(f"âŒ éŒ¯èª¤é¡å‹: {type(migration_error).__name__}")
                logger.error(f"âŒ éŒ¯èª¤è©³æƒ…: {str(migration_error)}")
                import traceback
                logger.error(f"âŒ å®Œæ•´å †ç–Šè¿½è¹¤:")
                logger.error(traceback.format_exc())
                logger.info("ğŸ”„ å›é€€åˆ°schema.sqlæ–¹å¼...")
                
                # å¦‚æœmigrationå¤±æ•—ï¼Œå›é€€åˆ°åŸä¾†çš„schema.sqlæ–¹å¼
                await self._create_tables_from_schema()
                
            logger.info("âœ… è³‡æ–™åº«è¡¨æ ¼å»ºç«‹æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ å»ºç«‹è³‡æ–™åº«è¡¨æ ¼å¤±æ•—: {e}")
            logger.error(f"âŒ éŒ¯èª¤é¡å‹: {type(e).__name__}")
            import traceback
            logger.error(f"âŒ å®Œæ•´å †ç–Šè¿½è¹¤:")
            logger.error(traceback.format_exc())
            raise

    async def _create_tables_from_schema(self):
        """å¾schema.sqlå»ºç«‹è³‡æ–™åº«è¡¨æ ¼ï¼ˆå‚™ç”¨æ–¹æ³•ï¼‰"""
        try:
            logger.info("ğŸ“‹ åŸ·è¡Œä¸»è¦è³‡æ–™åº«schema...")
            
            # è®€å–schema.sqlæª”æ¡ˆ
            schema_path = os.path.join(os.path.dirname(__file__), "schema.sql")
            logger.info(f"SQLæª”æ¡ˆåŸ·è¡Œä¸­: {schema_path}")
            
            with open(schema_path, 'r', encoding='utf-8') as f:
                schema_sql = f.read()
            
            # æ›¿æ›CREATE TABLEç‚ºCREATE TABLE IF NOT EXISTS
            schema_sql = schema_sql.replace("CREATE TABLE ", "CREATE TABLE IF NOT EXISTS ")
            
            # åŸ·è¡Œschema
            async with self.async_engine.begin() as conn:
                # åˆ†å‰²SQLèªå¥ä¸¦åŸ·è¡Œ
                statements = [stmt.strip() for stmt in schema_sql.split(';') if stmt.strip()]
                
                for statement in statements:
                    if statement:
                        try:
                            await conn.execute(text(statement))
                        except Exception as stmt_error:
                            # å¿½ç•¥å·²å­˜åœ¨çš„è¡¨æ ¼éŒ¯èª¤ï¼Œä½†è¨˜éŒ„å…¶ä»–éŒ¯èª¤
                            if "already exists" not in str(stmt_error):
                                logger.warning(f"åŸ·è¡ŒSQLèªå¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {stmt_error}")
                                logger.debug(f"å‡ºéŒ¯çš„SQLèªå¥: {statement}")
                            
            logger.info("âœ… Schema.sqlåŸ·è¡Œå®Œæˆ")
            
        except Exception as e:
            logger.error(f"åŸ·è¡Œschema.sqlå¤±æ•—: {e}")
            raise
    
    async def check_connection(self) -> bool:
        """æª¢æŸ¥è³‡æ–™åº«é€£ç·šç‹€æ…‹"""
        try:
            session = self.async_session_maker()
            async with session:
                result = await session.execute(text("SELECT 1"))
                return result.scalar() == 1
        except Exception as e:
            logger.error(f"è³‡æ–™åº«é€£ç·šæª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    async def get_async_session(self) -> AsyncSession:
        """å–å¾—ç•°æ­¥è³‡æ–™åº«session"""
        if not self.async_session_maker:
            await self.initialize()
        
        return self.async_session_maker()
    
    def get_session(self):
        """å–å¾—åŒæ­¥è³‡æ–™åº«session"""
        if not self.session_maker:
            raise RuntimeError("è³‡æ–™åº«æœªåˆå§‹åŒ–")
        return self.session_maker()
    
    async def close(self):
        """é—œé–‰è³‡æ–™åº«é€£ç·š"""
        if self.async_engine:
            await self.async_engine.dispose()
        if self.engine:
            self.engine.dispose()
        
        logger.info("è³‡æ–™åº«é€£ç·šå·²é—œé–‰")

# å…¨åŸŸè³‡æ–™åº«ç®¡ç†å™¨å¯¦ä¾‹
db_manager = DatabaseManager()

async def get_async_db() -> AsyncGenerator[AsyncSession, None]:
    """FastAPIä¾è³´æ³¨å…¥ï¼šå–å¾—ç•°æ­¥è³‡æ–™åº«session"""
    async with db_manager.get_async_session() as session:
        try:
            yield session
        except Exception as e:
            await session.rollback()
            logger.error(f"è³‡æ–™åº«æ“ä½œéŒ¯èª¤: {e}")
            raise
        finally:
            await session.close()

def get_db():
    """FastAPIä¾è³´æ³¨å…¥ï¼šå–å¾—åŒæ­¥è³‡æ–™åº«session"""
    db = db_manager.get_session()
    try:
        yield db
    except Exception as e:
        db.rollback()
        logger.error(f"è³‡æ–™åº«æ“ä½œéŒ¯èª¤: {e}")
        raise
    finally:
        db.close()

async def init_database():
    """åˆå§‹åŒ–è³‡æ–™åº«ï¼ˆç”¨æ–¼æ‡‰ç”¨å•Ÿå‹•æ™‚ï¼‰"""
    try:
        await db_manager.initialize()
        await db_manager.create_tables()
        
        # æª¢æŸ¥é€£ç·š
        if await db_manager.check_connection():
            logger.info("è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆä¸¦é€£ç·šæˆåŠŸ")
        else:
            raise ConnectionError("è³‡æ–™åº«é€£ç·šå¤±æ•—")
            
    except Exception as e:
        logger.error(f"è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
        raise

async def close_database():
    """é—œé–‰è³‡æ–™åº«é€£ç·šï¼ˆç”¨æ–¼æ‡‰ç”¨é—œé–‰æ™‚ï¼‰"""
    await db_manager.close()

# ç”¨æ–¼æ¸¬è©¦çš„å·¥å…·å‡½æ•¸
async def reset_database():
    """é‡è¨­è³‡æ–™åº«ï¼ˆåƒ…ç”¨æ–¼æ¸¬è©¦ï¼‰"""
    if not os.getenv("TESTING"):
        raise RuntimeError("åªèƒ½åœ¨æ¸¬è©¦ç’°å¢ƒä¸­é‡è¨­è³‡æ–™åº«")
    
    async with db_manager.async_engine.begin() as conn:
        # åˆªé™¤æ‰€æœ‰è¡¨æ ¼
        await conn.execute(text("""
            DROP SCHEMA public CASCADE;
            CREATE SCHEMA public;
            GRANT ALL ON SCHEMA public TO postgres;
            GRANT ALL ON SCHEMA public TO public;
        """))
    
    # é‡æ–°å»ºç«‹è¡¨æ ¼
    await db_manager.create_tables()
    logger.info("æ¸¬è©¦è³‡æ–™åº«å·²é‡è¨­")

if __name__ == "__main__":
    # æ¸¬è©¦è³‡æ–™åº«é€£ç·š
    async def test_connection():
        await init_database()
        
        # æ¸¬è©¦åŸºæœ¬æŸ¥è©¢
        async with db_manager.get_async_session() as session:
            result = await session.execute(text("SELECT COUNT(*) FROM papers"))
            count = result.scalar()
            print(f"Papers table count: {count}")
        
        await close_database()
    
    asyncio.run(test_connection()) 